\noindent \textbf{9.9} Suppose that $x_{1:n}$ and $x_{n:n}$ are the smallest and largest observed values of a random sample of size n from a distribution with pdf $f(x;\theta); 0<\theta$\\

a) if $f(x;\theta)=1$ for $\theta-0.5 \le x \le \theta +0.5$, zero otherwise, show that any value $\hat(\theta)$ such that $x_{n:n}-0.5 \le \hat(\theta) \le x_{1:n}+0.5$ is an ML estimate of $\theta$.


solutions:$L(\theta )=1 $for$\theta-0.5\le { x }_{ 1:n }$ and$ { x }_{ n:n }\ge \theta +0.5$, and$ l(\theta) = 0 $otherwise. Therefore, as long as $ {x}_{n:n}-0.5 \le \hat { \theta  } \le {x}_{1:n}+0.5$, we have an MLE.



b) if $f(x;\theta)=\frac{1}{\theta}$ for $\theta \le x \le 2\theta$, zero otherwise, show that any value $\hat(\theta)=0.5x_{n:n}$ is an ML estimate of $\theta$.

solutions:$ L(\theta)=\frac { 1 }{ { \theta  }^{ n } }$ if $(\theta) \le {x}_{1:n}$ and ${x}_{n:n}\le 2(\theta) $ or if$ \frac { { x }_{ n:n } }{ 2 } \le (\theta) \le {x}_{1:n}. L(\theta)$ is maximized in this interval when$ (\theta)$ is minimized, so we must have $\hat { \theta  } = \frac { { x }_{ n:n } }{ 2 } $as the MLE.
